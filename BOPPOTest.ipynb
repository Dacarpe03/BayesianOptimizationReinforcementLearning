{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNYhXr7O3/CEf/01O44zBkC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["## Step 1: Install dependencies"],"metadata":{"id":"W8SffEvs5opx"}},{"cell_type":"code","source":["!pip install importlib-metadata==4.12.0 # To overcome an issue with importlib-metadata https://stackoverflow.com/questions/73929564/entrypoints-object-has-no-attribute-get-digital-ocean\n","!pip install gym[box2d]\n","!pip install stable-baselines3[extra]\n","!pip install pyglet==1.5.1\n","!pip install ale-py==0.7.4 # To overcome an issue with gym (https://github.com/DLR-RM/stable-baselines3/issues/875)\n","!pip install botorch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MSx7znsRcHfl","outputId":"502d6d95-8c92-49e3-aab4-0ef9f9c8c873"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting importlib-metadata==4.12.0\n","  Downloading importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata==4.12.0) (3.13.0)\n","Installing collected packages: importlib-metadata\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 6.0.0\n","    Uninstalling importlib-metadata-6.0.0:\n","      Successfully uninstalled importlib-metadata-6.0.0\n","Successfully installed importlib-metadata-4.12.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.8/dist-packages (0.25.2)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (1.21.6)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (0.0.8)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (2.2.1)\n","Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (4.12.0)\n","Collecting swig==4.*\n","  Downloading swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pygame==2.1.0\n","  Downloading pygame-2.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting box2d-py==2.3.5\n","  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 KB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym[box2d]) (3.13.0)\n","Building wheels for collected packages: box2d-py\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\n","\u001b[0m\u001b[?25h  Running setup.py clean for box2d-py\n","Failed to build box2d-py\n","Installing collected packages: swig, box2d-py, pygame\n","  Running setup.py install for box2d-py ... \u001b[?25l\u001b[?25hdone\n","\u001b[33m  DEPRECATION: box2d-py was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. Discussion can be found at https://github.com/pypa/pip/issues/8368\u001b[0m\u001b[33m\n","\u001b[0mSuccessfully installed box2d-py-2.3.5 pygame-2.1.0 swig-4.1.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting stable-baselines3[extra]\n","  Downloading stable_baselines3-1.7.0-py3-none-any.whl (171 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.8/171.8 KB\u001b[0m \u001b[31m815.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]) (1.3.5)\n","Collecting gym==0.21\n","  Downloading gym-0.21.0.tar.gz (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]) (1.13.1+cu116)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]) (3.2.2)\n","Collecting importlib-metadata~=4.13\n","  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]) (1.21.6)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]) (2.2.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]) (7.1.2)\n","Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]) (2.11.2)\n","Collecting autorom[accept-rom-license]~=0.4.2\n","  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Collecting ale-py==0.7.4\n","  Downloading ale_py-0.7.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rich\n","  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 KB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]) (4.64.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]) (4.6.0.66)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]) (5.4.8)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from ale-py==0.7.4->stable-baselines3[extra]) (5.10.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.25.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (7.1.2)\n","Collecting AutoROM.accept-rom-license\n","  Downloading AutoROM.accept-rom-license-0.5.5.tar.gz (22 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata~=4.13->stable-baselines3[extra]) (3.13.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (57.4.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.16.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.0.1)\n","Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.19.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.8.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.38.4)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.6.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.51.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.11->stable-baselines3[extra]) (4.5.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.4)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->stable-baselines3[extra]) (2022.7.1)\n","Collecting markdown-it-py<3.0.0,>=2.1.0\n","  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pygments<3.0.0,>=2.14.0\n","  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (1.15.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n","Collecting mdurl~=0.1\n","  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2022.12.7)\n","Collecting libtorrent\n","  Using cached libtorrent-2.0.7-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (8.6 MB)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n","Building wheels for collected packages: gym, AutoROM.accept-rom-license\n","  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616821 sha256=5405d3fd1069699a5966974c636c221090eb6764de030ac299618da642e95e83\n","  Stored in directory: /root/.cache/pip/wheels/27/6d/b3/a3a6e10704795c9b9000f1ab2dc480dfe7bed42f5972806e73\n","  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.5.5-py3-none-any.whl size=441098 sha256=9b44d6d3ab480f7feb6cba21d798553c120b2119a6ab1edf038c2d4e7e6adef3\n","  Stored in directory: /root/.cache/pip/wheels/c3/86/6f/e96885ff274388b9f0636418a2926f46f076cd7e891670321d\n","Successfully built gym AutoROM.accept-rom-license\n","Installing collected packages: libtorrent, pygments, mdurl, importlib-metadata, gym, markdown-it-py, AutoROM.accept-rom-license, autorom, ale-py, stable-baselines3, rich\n","  Attempting uninstall: pygments\n","    Found existing installation: Pygments 2.6.1\n","    Uninstalling Pygments-2.6.1:\n","      Successfully uninstalled Pygments-2.6.1\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 4.12.0\n","    Uninstalling importlib-metadata-4.12.0:\n","      Successfully uninstalled importlib-metadata-4.12.0\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.25.2\n","    Uninstalling gym-0.25.2:\n","      Successfully uninstalled gym-0.25.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed AutoROM.accept-rom-license-0.5.5 ale-py-0.7.4 autorom-0.4.2 gym-0.21.0 importlib-metadata-4.13.0 libtorrent-2.0.7 markdown-it-py-2.2.0 mdurl-0.1.2 pygments-2.14.0 rich-13.3.1 stable-baselines3-1.7.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyglet==1.5.1\n","  Downloading pyglet-1.5.1-py2.py3-none-any.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["## Step 2: Import libraries"],"metadata":{"id":"daSuyCkE6B3M"}},{"cell_type":"code","source":["import os\n","import torch\n","import numpy as np\n","import plotly\n","\n","import gym\n","\n","from stable_baselines3 import PPO\n","from stable_baselines3.common.evaluation import evaluate_policy\n","from stable_baselines3.common.env_util import make_vec_env"],"metadata":{"id":"4VzDcFWQdXlz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 3: Define hyperparameters"],"metadata":{"id":"yWskfpJP6JJg"}},{"cell_type":"code","source":["rl_env_name = 'LunarLander-v2'"],"metadata":{"id":"uHJzyB5a6T0s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["policy = 'MlpPolicy'\n","env = make_vec_env(rl_env_name)\n","n_steps = 1024\n","batch_size = 64\n","n_epochs = 4\n","gamma = 0.999\n","gae_lambda = 0.98\n","ent_coef = 0.01\n","\n","hyperparams_list = [n_steps, batch_size, n_epochs, gamma, gae_lambda, ent_coef]\n","lower_bounds = [100, 8, 2, 0.8, 0.8, 0.001]\n","upper_bounds = [4000, 256, 10, 0.999, 0.999, 0.05]"],"metadata":{"id":"ZMw8O9ZGdNaW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Convert lists to tensors"],"metadata":{"id":"k0CyVEweE8r7"}},{"cell_type":"code","source":["hyperparams_tensor = torch.DoubleTensor([hyperparams_list])\n","bounds_tensor = torch.DoubleTensor([lower_bounds, upper_bounds])"],"metadata":{"id":"wE--qm4KE_tX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 4: Create initial results"],"metadata":{"id":"1n2iAqMh6tp1"}},{"cell_type":"code","source":["def get_hyp_values(hyperparams_tensor):\n","  hyperparameters_list = [hyperparams_tensor[0][i].item() for i in range(len(hyperparams_tensor[0]))]\n","  return tuple(hyperparameters_list)\n","\n","\n","def create_model(policy,\n","                 env,\n","                 hyperparams):\n","  \n","  n_steps, batch_size, n_epochs, gamma, gae_lambda, ent_coef = get_hyp_values(hyperparams)\n","  model = PPO(policy = policy,\n","              env = env,\n","              n_steps = 1024,\n","              batch_size = 64,\n","              n_epochs = 4,\n","              gamma = 0.999,\n","              gae_lambda = 0.98,\n","              ent_coef = 0.01,\n","              verbose=0)\n","  \n","  return  model\n","\n","def train_model(model):\n","  model.learn(total_timesteps=10000)\n","  return\n","\n","def evaluate_model(model):\n","  eval_env = gym.make(\"LunarLander-v2\")\n","  mean_reward, std_reward = evaluate_policy(model, \n","                                            eval_env, \n","                                            n_eval_episodes=10, \n","                                            deterministic=True)\n","  \n","  print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")\n","  return torch.DoubleTensor([[mean_reward]])\n"],"metadata":{"id":"dgSWx5En62Qr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = create_model(policy, \n","                     env, \n","                     hyperparams_tensor)"],"metadata":{"id":"Wkr8bda9eQh9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train the model for the firs time"],"metadata":{"id":"Epvc_jO0ISH0"}},{"cell_type":"code","source":["# Train for timesteps\n","train_model(model)"],"metadata":{"id":"0CQYYuFOerDM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Evaluate the model, create the rewards tensor (init_y) and get the best reward"],"metadata":{"id":"F6ibCxoIIT_8"}},{"cell_type":"code","source":["rewards_tensor = evaluate_model(model)\n","best_reward = rewards_tensor.min().item()"],"metadata":{"id":"R_f_UleHgBBN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 4: Use Gaussian Process with initial data"],"metadata":{"id":"Bz4Go0lx-3pq"}},{"cell_type":"markdown","source":["We set which model and which likelihood will we use. In our case we will use a classic Gaussian process and compute its hyper-parameters using the exact marginal log likelihood (which can produce overfitting when points are reduced but well...)"],"metadata":{"id":"BshOe69eI7ok"}},{"cell_type":"code","source":["from botorch.models import SingleTaskGP, ModelListGP\n","from gpytorch.mlls import LeaveOneOutPseudoLikelihood, ExactMarginalLogLikelihood\n","from botorch.models.transforms.outcome import Standardize\n","\n","single_model = SingleTaskGP(hyperparams_tensor, \n","                            rewards_tensor, \n","                            outcome_transform=Standardize(m=1))\n","\n","mll = ExactMarginalLogLikelihood(single_model.likelihood, \n","                                 single_model)"],"metadata":{"id":"mIMpzMAzCWVS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now that our model is declared, we fit the previous points with the Gaussian process setting its hyperparameters via Exact Marginal log likelihood of the points. The output shows the default covariance function used by the GP and its hyper-hyperparameters. It also shows the Gaussian likelihood used and the homoskedastic noise added to the Matern Kernel to capture the noise of the data. "],"metadata":{"id":"g0UYNB2ZI_pn"}},{"cell_type":"code","source":["from botorch import fit_gpytorch_model\n","fit_gpytorch_model(mll)"],"metadata":{"id":"AzL1JHQQCgTq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we declare the acquisition function that is going to be computed using the predictive distribution of the previous Gaussian process in all the input space. We will use the upper confidence bound."],"metadata":{"id":"SqLu_5z7JBgm"}},{"cell_type":"code","source":["from botorch.acquisition.analytic import UpperConfidenceBound #use the noisy version if the problem has noise\n","\n","UCB = UpperConfidenceBound(model=single_model, \n","                           beta=0.1, \n","                           maximize=False)"],"metadata":{"id":"Zhdx8w3gIq30"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We will now optimize the acquisition function, all the hyper parameters here are a good heuristic default to try and find the global optima of the acquisition function"],"metadata":{"id":"D224R6AtLhCU"}},{"cell_type":"code","source":["from botorch.optim import optimize_acqf\n","\n","candidates, _ = optimize_acqf(acq_function=UCB, \n","                              bounds=bounds_tensor, \n","                              q=1, \n","                              num_restarts=200,\n","                              raw_samples=512, \n","                              options={\"batch_limit\": 5, \"maxiter\": 200})\n","candidates"],"metadata":{"id":"YZgdSdO6Lk-3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We now have all the code of an iteration so we just put it in a loop. To do so: We just wrap previous code into a function.\n","\n"],"metadata":{"id":"137ae6AUKxLy"}},{"cell_type":"code","source":["def get_next_hyperparameters(hyperparams_tensor,\n","                             rewards_tensor,\n","                             best_reward,\n","                             bounds_tensor,\n","                             n_points=1,\n","                             noise=np.float64(0.07)\n","                             ):\n","  single_model = SingleTaskGP(hyperparams_tensor,\n","                              rewards_tensor,\n","                              outcome_transform=Standardize(m=1))\n","  mll = ExactMarginalLogLikelihood(single_model.likelihood, \n","                                   single_model)\n","  fit_gpytorch_model(mll)\n","\n","  UCB = UpperConfidenceBound(model=single_model,\n","                             beta=0.2, \n","                             maximize=True)\n","  \n","  candidates, _ = optimize_acqf(acq_function=UCB,\n","                                bounds=bounds_tensor,\n","                                q=n_points, \n","                                num_restarts=100,\n","                                raw_samples=512,\n","                                options={\"batch_limit\": 5, \"maxiter\": 200})\n","  \n","  return candidates"],"metadata":{"id":"za7xpLWtJRB_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Finally, we embed the previous code into the Bayesian optimization loop"],"metadata":{"id":"K1fLHtYVMJvX"}},{"cell_type":"code","source":["n_iterations = 5\n","\n","for i in range(n_iterations):\n","  print(f\"Number of iterations done: {i}\")\n","  new_hyperparams = get_next_hyperparameters(hyperparams_tensor, \n","                                            rewards_tensor, \n","                                            best_reward, \n","                                            bounds_tensor, \n","                                            1)\n","  print(new_hyperparams)\n","  \n","  model = create_model(policy,\n","                       env,\n","                       new_hyperparams)\n","  train_model(model)\n","  new_reward = evaluate_model(model)\n","  \n","  print(f\"New candidates are: {new_hyperparams}\")\n","  hyperparams_tensor = torch.cat([hyperparams_tensor, new_hyperparams])\n","  rewards_tensor = torch.cat([rewards_tensor, new_reward])\n"," \n","  best_reward = rewards_tensor.max().item()\n","  print(f\"Best hyperparameters get this mean reward: {best_reward}\")"],"metadata":{"id":"p60IwjsbMCcQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"b0dMJZFuNedm"},"execution_count":null,"outputs":[]}]}